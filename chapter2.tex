\chapter{Related Work}

In this chapter, we present the most relevant research results that guided our work, exposing the methodologies used by the authors and how they correlate to ours. Research on automatic pain assessment has a significant intersection between the medical field and applied machine learning both for fetuses and infants \citep{ZamzmiPGKSA16, Bellieni2012}. Thus, we start by exploring the signs of pain in infants and fetuses, their main indicators, the available pain scales measure them, and automatic methods of assessment. We conclude the chapter by explaining how our work is different from the mentioned ones as we explore automatic pain assessment from a novel perspective with fetuses.

\section{Pain}

Pain is a universal form of distress present in humans and some other animals. Acute and chronic pain is very typical in the population and constitutes widespread public health problems \citep{Goldberg2011}. Its prolonged presence could cause many adverse consequences, including psychological effects, which is especially true in the case of neonates and fetuses.

The study of neonatal pain appears to have begun as early as the 1870s when Dr. Flechsig proposed it was unlikely that neonates could feel pain because their neuronal myelination was not complete \citep{cope1998neonatal}. Charles Darwin's book written a couple of years later agreed with this view, as he wrote that ``an infant's pain expressions were related to reflexes only'' \citep{darwin1872expression}. Even in the 1950s, some pediatric surgeries were still performed without analgesia and anesthesia \citep{cope1998neonatal}.

It was only in the early 1980s that the first fetal surgery was performed by Dr. Michael Harrison \citep{Harrison1982}. The fetus to be operated had a blockage in the urinary tract that caused the kidney to dangerously extend, which is a condition known as congenital hydronephrosis. A vesicostomy was conducted to correct this issue by placing a catheter in the fetus to allow the urine to be released normally.

Further progress has been made in the years since this first operation, as advances in imaging technology and in surgery techniques allowed additional abnormalities to be treated and for less invasive forms of fetal surgical intervention to be performed.

Even though the cases in which fetal surgery is necessary are relatively rare, it has become the standard form of intervention in some abnormalities like myelomeningocele, as shown by the Management of Myelomeningocele (MOMs) Trial \citep{Adzick2011}. The study compared outcomes of in utero repair (before birth) with standard postnatal repair (after birth). The conclusion was that prenatal repair might result in better neurologic function than repair deferred until after delivery.

As shown by \cite{Devoto2017}, fetal pain is among the main concerns of anaesthesiologists during fetal surgery for myelomeningocele. Thus pain assessment and management are of fundamental help in those risky procedures, and its study is highly correlated to fetal therapy and fetal surgery.

\subsection{Pain Indicators}

Fetuses and infants can produce different signals of pain, which can be decoded to both identify its presence and to measure its level. These signals come from a variety of sources, such as facial expressions, crying sounds, body movements, physiological indicators, and biological markers \citep{Bellieni2012}. 

Even though we have this many indicators, pain identification is a challenging task as we have the manifestation of the same indicators present in similar feelings, such as anger, hunger, or stress. The recommendation to address this issue is that these indicators should be used in combination with each other \citep{Bellieni2012} because most of the time, their presence alone is not sufficient. 

Crying, for instance, can also be generated by hunger or anger. Therefore it can not be used as a sole indicator of pain. In the past, it was believed that different emotions resulted in different types of crying, but this theory has been refuted as it was later discovered that what causes the difference is not the cause of distress, but rather its intensity. 

Thus, some pain scales combine features of crying with other indicators for pain assessment. Fetuses have been shown to express a homolog of crying \citep{Gingras2005}, which can also be further explored for automatic pain assessment, as shown by \cite{abs-1909-02543}. 

Physiological indicators, on the other hand, have the limitation that they are subject to variations due to underlying illness \citep{sweet1998physiological}. Body movements have also been pointed out to be indicators of pain, as fetuses already present withdrawn reflexes during stressful procedures \citep{Zimmermann1991}, but care must be taken as they can also be misleading as other factors may cause the movements.

Studies have also shown that biological markers like stress hormones (cortisol, adrenaline, and beta-endorphins) are increased in concentration in the blood in the presence of pain \citep{giannakoulopoulos1994fetal}. However, the problem of these indicators is that they depend on results from laboratory tests, which makes it unfeasible to use during clinal trials.

One of the most relevant indicators of pain, not only in adults but also in neonates and fetuses are facial expressions. As suggested by \cite{Yan2006}, a great way of evaluating fetal facial expressions is through the means of 4-D sonography, and as he points out, these studies may be the key to predicting fetal brain function and well-being. Later research by \cite{Reissland2011, Reissland2013} also suggests that, when healthy fetuses mature from 24 to 26 weeks of gestation, their capability of showing complex facial movements increases, and they were even able to observe facial expressions which resemble a face while in pain or distress.

Facial expression indicators are frequently present in pain scales. Several facial movements are usually tracked, such as brow bulge, eye squeeze, nasolabial furrow, and open mouth. The assessment of these manifestations is done by observers, which use pain scales to identify its presence and intensity of pain.

\subsection{Pain Scales}

Various neonatal pain scales were developed using the many indicators mentioned in the previous section. These multidimensional scales are used by caregivers to assess pain with behavioral and physiological indicators. The most common scales are:

\begin{itemize}
    \item Neonatal Infant Pain Scale (NIPS), by \cite{Lawrence1993}
    \item Face, Legs, Activity, Crying and Consolability (FLACC), by \cite{Merkel1996}
    \item Neonatal Facial Coding System (NFCS), by \cite{Grunau1998}
\end{itemize}

These scales were all developed with neonates in mind, as some indicators observations are not easily measured in a fetus. However, recent studies by \citeauthor{bernardes2018feasibility} have reported that the use of the NFCS is feasible to detect pain-related facial expressions compared with the rest condition in a randomized and blinded assessment report. We further discuss this study in Chapter 4.

Nevertheless, the scales also have some limitations, as they are highly dependent on the observant bias, require specific training for proper utilization, and are not able to monitor pain in a continuous manner. Thus developing tools that are capable of doing this job automatically and continuously is highly compelling as they can generate a more consistent pain assessment.

\section{Automatic Pain Assessment}

The development of learning models to automatically assess pain is has been a topic of research for a long time. As an example, in the adult's domain, \citep{MauricioCVC19} has achieved remarkable results in identifying spatiotemporal features extracted from video sequences for pain recognition.

The first work attempting to assess pain in newborns automatically emerged in 2004 with the development of the iCOPE database \citep{Brahnam2006}. At the time, neural networks were not as popular and advanced as they are today. The first attempts made use of traditional techniques such as PCA, LDA, and SVM. Still, the results were satisfactory, and the experimental process they developed is similar to what is used today. 

Their database consisted of 216 images from 26 infants being 13 girls and 13 boys. The images were collected in 5 different conditions, a resting baseline, bodily disturbance, an air stimulus on the nose, friction on the external surface of the heel, and the pain of a heel stick. The idea behind using this number of conditions was to make the set of images representative, but also challenging enough. The five conditions were later divided into two groups for classification: pain and non-pain.

Our work as adopted a similar approach of not having only images of rest and pain, but we have also added a third set of images from other stimuli of a horn, which had the intention of causing discomfort, but no pain. 

Their first studies considered the best scenario where the system would be able to train on a fetus and evaluate that same fetus later on. However, as permanence in the baby nursery is quite short, they also had to consider the case where this was not possible. Thus the validation process had to consider the other scenario where the classifier had to be trained beforehand and evaluated on images of a new baby, which was not in the dataset distribution previously.

Given they had a small number of subjects, it was feasible to use a validation strategy known as leave-one-out, which consisted of iterating over every combination of using 25 subjects for training and 1 for testing. We have adopted the same strategy in our work.

\section{Learning Models for Pain Assessment}

As opposed to past work, like \citep{ZhiZGALS18}, which used filters and descriptors to extract features from images, modern approaches in automatic pain assessment of neonates usually make the use of neural networks to achieve state of the art results.

\cite{abs-1807-01631}, for instance, has significantly improved the results in the aforementioned iCOPE dataset, achieving 0.948 of AUC by combining both handcrafted features and features extracted by CNNs.

\cite{SalekinZGKH019} proposed a multi-channel shared network to classify pain from videos by extracting features from facial expressions and body movements. He also contributed with an alternative approach by using convolutional neural networks to extract features from crying sounds \citep{abs-1909-02543}.

% In general, much like the pain scales, a combination of features from different inputs is what tends to work best. 